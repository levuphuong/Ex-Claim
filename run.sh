#!/bin/bash

echo "STEP 1: create directory"
mkdir -p outputs/Data/CheckThat-2022/english/verifiable-claim-detection

echo "===== DOWNLOAD & PREPARE CHECKTHAT 2022 DATASETS ====="

# =========================
# Language configurations
# =========================
declare -A LANG_URLS

LANG_URLS=(
  ["english"]="https://gitlab.com/checkthat_lab/clef2022-checkthat-lab/clef2022-checkthat-lab/-/raw/main/task1/data/subtasks-english/CT22_english_1A_checkworthy.zip?inline=false"
  ["dutch"]="https://gitlab.com/checkthat_lab/clef2022-checkthat-lab/clef2022-checkthat-lab/-/raw/main/task1/data/subtasks-dutch/CT22_dutch_1A_checkworthy.zip?inline=false"
)


TEST_URLS=(
  ["english"]="https://gitlab.com/checkthat_lab/clef2022-checkthat-lab/clef2022-checkthat-lab/-/raw/main/task1/data/subtasks-english/CT22_english_1B_claim.zip?inline=false"
  ["dutch"]="https://gitlab.com/checkthat_lab/clef2022-checkthat-lab/clef2022-checkthat-lab/-/raw/main/task1/data/subtasks-dutch/test/CT22_dutch_1B_claim_test.zip?inline=false"
)

BASE_OUTPUT="outputs/Data/CheckThat-2022"

# =========================
# Loop over languages
# =========================
for LANG in "${!LANG_URLS[@]}"; do
  echo "======================================"
  echo "Processing language: $LANG"
  echo "======================================"

  ZIP_FILE="CT22_${LANG}_1A.zip"
  TMP_DIR="ct22_${LANG}_tmp"
  OUT_DIR="$BASE_OUTPUT/$LANG/verifiable-claim-detection"

  # -------------------------
  # Train / Dev
  # -------------------------
  echo "STEP 1: download train/dev dataset"
  wget -q -O "$ZIP_FILE" "${LANG_URLS[$LANG]}"

  echo "STEP 2: unzip train/dev"
  rm -rf "$TMP_DIR"
  mkdir -p "$TMP_DIR"
  unzip -q "$ZIP_FILE" -d "$TMP_DIR"

  echo "STEP 3: locate files"
  TRAIN_FILE=$(find "$TMP_DIR" -iname "*train.tsv" | head -n 1)
  DEV_FILE=$(find "$TMP_DIR" -iname "*dev.tsv" | head -n 1)
  DEV_TEST_FILE=$(find "$TMP_DIR" -iname "*dev_test.tsv" | head -n 1)

  echo "  train = $TRAIN_FILE"
  echo "  dev   = $DEV_FILE"

  echo "STEP 4: copy train/dev"
  mkdir -p "$OUT_DIR"
  cp "$TRAIN_FILE" "$OUT_DIR/train.tsv"
  cp "$DEV_FILE"   "$OUT_DIR/dev.tsv"
  cp "$DEV_FILE"   "$OUT_DIR/dev_test.tsv"

  # -------------------------
  # Test (n·∫øu c√≥ URL ri√™ng)
  # -------------------------
  if [[ -n "${TEST_URLS[$LANG]}" ]]; then
    echo "STEP 5: download test dataset"
    TEST_ZIP="CT22_${LANG}_test.zip"
    TEST_TMP="${TMP_DIR}_test"

    wget -q -O "$TEST_ZIP" "${TEST_URLS[$LANG]}"

    echo "STEP 6: unzip test"
    rm -rf "$TEST_TMP"
    mkdir -p "$TEST_TMP"
    unzip -q "$TEST_ZIP" -d "$TEST_TMP"

    TEST_FILE=$(find "$TEST_TMP" -iname "*test*.tsv" | head -n 1)

    echo "  test  = $TEST_FILE"

    cp "$TEST_FILE" "$OUT_DIR/test.tsv"
  else
    echo "STEP 5: no official test ‚Üí fallback to dev"
    cp "$OUT_DIR/dev.tsv" "$OUT_DIR/dev_test.tsv"
  fi

  echo "DONE: $LANG"
  echo
done

echo "===== ALL LANGUAGES PROCESSED ====="

echo "===== Downloading mGENRE pretrained model ====="

# MODEL_DIR="outputs/Pretrained-models/mGENRE"
# mkdir -p ${MODEL_DIR}

# # # C√†i CLI m·ªõi
# # pip install --quiet huggingface_hub

# # Download trie (B·∫ÆT BU·ªòC)
# hf download facebook/mgenre-wiki \
#   titles_lang_all105_marisa_trie_with_redirect.pkl \
#   --local-dir ${MODEL_DIR}

# echo "‚úì Downloaded titles_lang_all105_marisa_trie_with_redirect.pkl"

# # (Optional nh∆∞ng n√™n c√≥)
# hf download facebook/mgenre-wiki \
#   config.json \
#   --local-dir ${MODEL_DIR}


  # ==============================
# CONFIG
# ==============================
# MODEL_DIR="outputs/Pretrained-models/mGENRE"
# MODEL_NAME="fairseq_multilingual_entity_disambiguation"

# mkdir -p ${MODEL_DIR}
# cd ${MODEL_DIR}

# echo "üìÅ Working directory: $(pwd)"

# # ==============================
# # DOWNLOAD MODEL (fairseq)
# # ==============================
# if [ ! -d "${MODEL_NAME}" ]; then
#     echo "‚¨áÔ∏è Downloading mGENRE fairseq model..."
#     wget -c https://dl.fbaipublicfiles.com/GENRE/${MODEL_NAME}.tar.gz
#     tar --no-same-owner -xvf ${MODEL_NAME}.tar.gz
#     rm ${MODEL_NAME}.tar.gz
# else
#     echo "‚úÖ Model already exists: ${MODEL_NAME}"
# fi

# echo "‚úì Downloaded config.json"

# echo "===== mGENRE download completed ====="
# # ls -lh ${MODEL_DIR}

# cd -


# echo "STEP 0: install missing python packages (debug)"
# pip install --no-cache-dir pandas==2.1.4

# echo "===== INSTALL RUNTIME DEPENDENCIES ====="

# pip install --no-cache-dir \
#     fastapi \
#     marisa-trie
#     pandas \
#     gensim \
#     tensorboardX \
#     sacremoses \
#     sentencepiece \
#     scikit-learn \
#     "scipy<1.12" \
#     "numpy<2.0"  \
#     "xlsxwriter"


# echo "===== DEPENDENCIES INSTALLED ====="


##############
export PYTHONPATH=$PWD

mkdir -p outputs/Logs
mkdir -p outputs/Models/Claim-Detection
mkdir -p outputs/Data/All
mkdir -p outputs/Results/Claim-Detection

cd outputs/Pretrained-models/mGENRE/fairseq_multilingual_entity_disambiguation
cp dict.source.txt dict.txt
cd -

python src/evaluation/claim-detectionE.py
# python download.py
